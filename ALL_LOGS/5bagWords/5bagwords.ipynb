{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018ea815-edd0-413c-ad31-8fa648f68c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Implement the Continuous Bag of Words (CBOW) Model. Stages can be:\n",
    "a. Data preparation\n",
    "b. Generate training data\n",
    "c. Train model\n",
    "d. Output\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "518ce991-8bff-4127-8d28-c9f2c3a74046",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,\\\n",
    "\tEmbedding, Lambda\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "870b19b9-67c9-4946-a3b6-64aa3e8e5fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a. Data preparation\n",
    "data = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fb3fabe-b0e7-4c1e-9454-7714c07f9253",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences = data.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "190dead5-ef9d-4da5-8a0f-c2c13f9f6972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We are about to study the idea of a computational process',\n",
       " '\\nComputational processes are abstract beings that inhabit computers',\n",
       " '\\nAs they evolve, processes manipulate other abstract things called data',\n",
       " '\\nThe evolution of a process is directed by a pattern of rules\\ncalled a program',\n",
       " ' People create programs to direct processes',\n",
       " ' In effect,\\nwe conjure the spirits of the computer with our spells',\n",
       " '']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3b1c918-4243-4ce2-b17a-0e99b98f7ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Clean Data\n",
    "clean_sentences = []\n",
    "for sentence in sentences:\n",
    "    # skip empty string\n",
    "    if sentence == \"\":\n",
    "        continue;\n",
    "    # remove special characters\n",
    "    sentence = re.sub('[^A-Za-z0-9]+', ' ', sentence)\n",
    "    # remove 1 letter words\n",
    "    sentence = re.sub(r'(?:^| )\\w(?:$| )', ' ', sentence).strip()\n",
    "    # lower all characters\n",
    "    sentence = sentence.lower()\n",
    "    clean_sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da6fdd9c-5805-4183-a66d-5b2665475302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we are about to study the idea of computational process',\n",
       " 'computational processes are abstract beings that inhabit computers',\n",
       " 'as they evolve processes manipulate other abstract things called data',\n",
       " 'the evolution of process is directed by pattern of rules called program',\n",
       " 'people create programs to direct processes',\n",
       " 'in effect we conjure the spirits of the computer with our spells']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clean_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0644e460-fbe8-47eb-bd02-353a4a3b7082",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the corpus\n",
    "corpus = clean_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19765f13-cfbc-46b3-9d86-721adc7a3902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After converting our words in the corpus into vector of integers:\n",
      "[[4, 5, 11, 6, 12, 1, 13, 2, 7, 8], [7, 3, 5, 9, 14, 15, 16, 17], [18, 19, 20, 3, 21, 22, 9, 23, 10, 24], [1, 25, 2, 8, 26, 27, 28, 29, 2, 30, 10, 31], [32, 33, 34, 6, 35, 3], [36, 37, 4, 38, 1, 39, 2, 1, 40, 41, 42, 43]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert the corpus to a sequence of integers\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "print(\"After converting our words in the corpus \\\n",
    "into vector of integers:\")\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab7327ee-05f6-4b98-9130-a3888a110ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 11, 6, 12, 1, 13, 2, 7, 8]\n",
      "['we', 'are', 'about', 'to', 'study', 'the', 'idea', 'of', 'computational', 'process']\n",
      "[7, 3, 5, 9, 14, 15, 16, 17]\n",
      "['computational', 'processes', 'are', 'abstract', 'beings', 'that', 'inhabit', 'computers']\n",
      "[18, 19, 20, 3, 21, 22, 9, 23, 10, 24]\n",
      "['as', 'they', 'evolve', 'processes', 'manipulate', 'other', 'abstract', 'things', 'called', 'data']\n",
      "[1, 25, 2, 8, 26, 27, 28, 29, 2, 30, 10, 31]\n",
      "['the', 'evolution', 'of', 'process', 'is', 'directed', 'by', 'pattern', 'of', 'rules', 'called', 'program']\n",
      "[32, 33, 34, 6, 35, 3]\n",
      "['people', 'create', 'programs', 'to', 'direct', 'processes']\n",
      "[36, 37, 4, 38, 1, 39, 2, 1, 40, 41, 42, 43]\n",
      "['in', 'effect', 'we', 'conjure', 'the', 'spirits', 'of', 'the', 'computer', 'with', 'our', 'spells']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# creating dictionary for word to index and index to word\n",
    "index_to_word_map = {}\n",
    "word_to_index_map = {}\n",
    "for index_1, sequence in enumerate(sequences):\n",
    "    print(sequence)\n",
    "    words_in_sentence = clean_sentences[index_1].split()\n",
    "    print(words_in_sentence)\n",
    "    for index_2, value in enumerate(sequence):\n",
    "        index_to_word_map[value] = words_in_sentence[index_2]\n",
    "        word_to_index_map[words_in_sentence[index_2]] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e9fd12b-cb23-4879-ad91-3f471ae0fea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4: 'we', 5: 'are', 11: 'about', 6: 'to', 12: 'study', 1: 'the', 13: 'idea', 2: 'of', 7: 'computational', 8: 'process', 3: 'processes', 9: 'abstract', 14: 'beings', 15: 'that', 16: 'inhabit', 17: 'computers', 18: 'as', 19: 'they', 20: 'evolve', 21: 'manipulate', 22: 'other', 23: 'things', 10: 'called', 24: 'data', 25: 'evolution', 26: 'is', 27: 'directed', 28: 'by', 29: 'pattern', 30: 'rules', 31: 'program', 32: 'people', 33: 'create', 34: 'programs', 35: 'direct', 36: 'in', 37: 'effect', 38: 'conjure', 39: 'spirits', 40: 'computer', 41: 'with', 42: 'our', 43: 'spells'}\n",
      "\n",
      "\n",
      "{'we': 4, 'are': 5, 'about': 11, 'to': 6, 'study': 12, 'the': 1, 'idea': 13, 'of': 2, 'computational': 7, 'process': 8, 'processes': 3, 'abstract': 9, 'beings': 14, 'that': 15, 'inhabit': 16, 'computers': 17, 'as': 18, 'they': 19, 'evolve': 20, 'manipulate': 21, 'other': 22, 'things': 23, 'called': 10, 'data': 24, 'evolution': 25, 'is': 26, 'directed': 27, 'by': 28, 'pattern': 29, 'rules': 30, 'program': 31, 'people': 32, 'create': 33, 'programs': 34, 'direct': 35, 'in': 36, 'effect': 37, 'conjure': 38, 'spirits': 39, 'computer': 40, 'with': 41, 'our': 42, 'spells': 43}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(index_to_word_map)\n",
    "print(\"\\n\")\n",
    "print(word_to_index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70f53115-44b9-41a3-9cc9-ac0b0a4d1801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gen training data\n",
    "\n",
    "# Define the parameters\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_size = 10\n",
    "window_size = 2\n",
    "\n",
    "# Generate the context-target pairs\n",
    "contexts = []\n",
    "targets = []\n",
    "for sequence in sequences:\n",
    "\tfor i in range(window_size, len(sequence) - window_size):\n",
    "\t\tcontext = sequence[i - window_size:i] + sequence[i + 1:i + window_size + 1]\n",
    "\t\ttarget = sequence[i]\n",
    "\t\tcontexts.append(context)\n",
    "\t\ttargets.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8ac594f-8614-4438-89a0-f821071d3124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'are', 'to', 'study'] => about\n",
      "['are', 'about', 'study', 'the'] => to\n",
      "['about', 'to', 'the', 'idea'] => study\n",
      "['to', 'study', 'idea', 'of'] => the\n",
      "['study', 'the', 'of', 'computational'] => idea\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# sample of training data\n",
    "for i in range(5):\n",
    "    words = []\n",
    "    target = index_to_word_map.get(targets[i])\n",
    "    for j in contexts[i]:\n",
    "        words.append(index_to_word_map.get(j))\n",
    "    print(words, \"=>\", target)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db7d971c-e5bb-4e95-b5c9-f4a5fab12826",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the contexts and targets to numpy arrays\n",
    "X = np.array(contexts)\n",
    "Y = np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62dd52b4-f739-4dd6-b8ed-468bbe77614d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#train  model \n",
    "\n",
    "# Define the CBOW model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=2 * window_size))\n",
    "model.add(Lambda(lambda x: tf.reduce_mean(x, axis=1)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(units=vocab_size, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a9af90-409a-45bb-80d2-42ea3fe1c395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
